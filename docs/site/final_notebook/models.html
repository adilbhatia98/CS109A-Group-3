<!DOCTYPE html>

<html lang="en-us">
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge">

  <title>Home - Trump Tweet VIX</title>
  <link rel="stylesheet" href="http://localhost:4000/assets/css/just-the-docs.css">
  
  <script type="text/javascript" src="http://localhost:4000/assets/js/vendor/lunr.min.js"></script>
  
  <script type="text/javascript" src="http://localhost:4000/assets/js/just-the-docs.js"></script>

  <meta name="viewport" content="width=device-width, initial-scale=1">
</head>


  <div class="page-wrap">
    <div class="side-bar">
      <a href="http://localhost:4000" class="site-title fs-6 lh-tight">Trump Tweet VIX</a>
      <span class="fs-3"><button class="js-main-nav-trigger navigation-list-toggle btn btn-outline" type="button" data-text-toggle="Hide">Menu</button></span>
      <div class="navigation main-nav js-main-nav">
        <nav>
  <ul class="navigation-list">
    
    
      
        
          <li class="navigation-list-item active">
            
            <a href="http://localhost:4000/" class="navigation-list-link active">Home</a>
            
          </li>
        
      
    
      
        
          <li class="navigation-list-item">
            
            <a href="http://localhost:4000/background.html" class="navigation-list-link">Background</a>
            
          </li>
        
      
    
      
        
          <li class="navigation-list-item">
            
            <a href="http://localhost:4000/final_notebook/data.html" class="navigation-list-link">Data Exploration</a>
            
          </li>
        
      
    
      
        
          <li class="navigation-list-item">
            
            <a href="http://localhost:4000/final_notebook/models.html" class="navigation-list-link">Models</a>
            
          </li>
        
      
    
      
        
          <li class="navigation-list-item">
            
            <a href="http://localhost:4000/conclusions.html" class="navigation-list-link">Conclusions</a>
            
          </li>
        
      
    
  </ul>
</nav>

      </div>
      <footer role="contentinfo" class="site-footer">
        <p class="text-small text-grey-dk-000 mb-0">This site uses <a href="https://github.com/pmarsceill/just-the-docs">Just the Docs</a>, a documentation theme for Jekyll.</p>
      </footer>
    </div>
    <div class="main-content-wrap">
      <div class="page-header">
        <div class="main-content">
          
          <div class="search js-search">
            <div class="search-input-wrap">
              <input type="text" class="js-search-input search-input" placeholder="Search Trump Tweet VIX" aria-label="Search Trump Tweet VIX" autocomplete="off">
              <svg width="14" height="14" viewBox="0 0 28 28" xmlns="http://www.w3.org/2000/svg" class="search-icon"><title>Search</title><g fill-rule="nonzero"><path d="M17.332 20.735c-5.537 0-10-4.6-10-10.247 0-5.646 4.463-10.247 10-10.247 5.536 0 10 4.601 10 10.247s-4.464 10.247-10 10.247zm0-4c3.3 0 6-2.783 6-6.247 0-3.463-2.7-6.247-6-6.247s-6 2.784-6 6.247c0 3.464 2.7 6.247 6 6.247z"/><path d="M11.672 13.791L.192 25.271 3.02 28.1 14.5 16.62z"/></g></svg>
            </div>
            <div class="js-search-results search-results-wrap"></div>
          </div>
          
          
            <ul class="list-style-none text-small mt-md-1 mb-md-1 pb-4 pb-md-0 js-aux-nav aux-nav">
              
                <li class="d-inline-block my-0"><a href="https://github.com/adilbhatia98/CS109A-Group-3">Trump Tweet VIX on GitHub</a></li>
              
            </ul>
          
        </div>
      </div>
      <div class="main-content">
        
          
        
        <div class="page-content">
          <h1 class="no_toc" id="models">Models</h1>

<h2 class="no_toc text-delta" id="table-of-contents">Table of contents</h2>

<ol id="markdown-toc">
  <li><a href="#setup" id="markdown-toc-setup">Setup</a></li>
  <li><a href="#baseline-model" id="markdown-toc-baseline-model">Baseline Model - Logistic</a></li>
  <li><a href="#l1-and-l2-regularization" id="markdown-toc-l1-and-l2-regularization">L1 and L2 Regularization</a></li>
  <li><a href="#random-forest" id="markdown-toc-random-forest">Random Forest</a></li>
  <li><a href="#boosting" id="markdown-toc-boosting">Boosting</a></li>
  <li><a href="#neural-networks" id="markdown-toc-neural-networks">Neural Networks</a></li>
  <li><a href="#model-selection" id="markdown-toc-model-selection">Model Selection</a></li>
</ol>

<hr />

<h1 id="setup">Setup</h1>
       
<p>Our goal for this project is to build a model that can accurately predict changes in VIX prices after Trump tweets. In the model, we use characteristics of the VIX data (like <code class="highlighter-rouge">Last Price</code>) and multiple characteristics of the Twitter data. Also, some predictors are common to both datasets, such as date/time predictors.</p>
          
<p>Based on these predictors, we initially considered two types of models. First, we considered one that predicts absolute price changes in VIX pricing (continuous outcome). Second, we considered one that predicts the sign of VIX pricing changes (positive, negative, or no change - a categorical outcome). Intuitively, given what we know about the VIX and its pricing fluctuations, we thought it made more sense to focus on a model that predicts the change in pricing. Thus, we built a model that has a categorical output variable: -1 for negative price delta, 0 for no price delta, 1 for positive price delta.</p>
  
<p>We also wanted to create interval versions of this model that looks at the VIX price change over 1 minute, 5, 10, 20 , 30, and 60 minutes. We wanted to consider all these options to determine the most accurate and most useful model. Realistically, if our model predicts well 10+ minutes after the tweet, it can offer a great chance to earn positive returns by trading on the VIX index. Another important consideration is the threshold at which we declare an outcome positive or negative. Given we are using minute-by-minute data, we decided upon a 0.001 threshold so that any change between -0.001 and 0.001 inclusive should be categorized as 0 (no price delta). To explain why we chose 0.001, there are a couple points to consider. First, any change is very helpful in terms of playing the market through trading, even if it is a small change. Second, a larger threshold could have potentially forced our models to disproportionately predict 0 change (at all time intervals), which would not be a useful model. As we will see below, at larger intervals, our models predict far fewer 0 outcomes, becoming more successful at predicting positive or negative changes in the VIX pricing over time.</p>  

<p>For each model trial, we first split our data into a train and test set, so that we are later able to assess how well our model performs in both a train set and a not-seen test set. Realistically, training accuracy reflects how well a given model 'understands' the data it is presented with, and testing accuracy reflects how well that model can be generalized to accurately form predictions about data it has not yet seen. For each time interval model, we drop the irrelevant time-based price predictors. For example, model30 does not include <code class="highlighter-rouge">price_delta_30</code> or <code class="highlighter-rouge">price_delta_60</code> as predictors. We perform this drop for each time interval model.</p>
          
<h1 id="baseline-model">Baseline Model - Logistic</h1>

<p>Our baseline model represents a simple logistic regression with a multiclass outcome variable. Using the predictors in our data, the model predicts the 'change in VIX price' classification as positive, negative, or 0 (no change) using a simple logistic regression.</p>          
         
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># 1 min</span>
<span class="n">logreg0</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train0</span><span class="p">,</span> <span class="n">y_train0</span><span class="p">)</span>
<span class="n">logreg_fit_train0</span> <span class="o">=</span> <span class="n">logreg0</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train0</span><span class="p">)</span>
<span class="n">logreg_fit_test0</span> <span class="o">=</span> <span class="n">logreg0</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test0</span><span class="p">)</span>

<span class="n">train_scores_logreg0</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train0</span><span class="p">,</span> <span class="n">logreg_fit_train0</span><span class="p">)</span>
<span class="n">test_scores_logreg0</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test0</span><span class="p">,</span> <span class="n">logreg_fit_test0</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training Accuracy 1 min: &quot;</span><span class="p">,</span> <span class="n">train_scores_logreg0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Testing Accuracy 1 min: &quot;</span><span class="p">,</span> <span class="n">test_scores_logreg0</span><span class="p">)</span>

<span class="c1"># 5 min</span>
<span class="n">logreg5</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train5</span><span class="p">,</span> <span class="n">y_train5</span><span class="p">)</span>
<span class="n">logreg_fit_train5</span> <span class="o">=</span> <span class="n">logreg5</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train5</span><span class="p">)</span>
<span class="n">logreg_fit_test5</span> <span class="o">=</span> <span class="n">logreg5</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test5</span><span class="p">)</span>

<span class="n">train_scores_logreg5</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train5</span><span class="p">,</span> <span class="n">logreg_fit_train5</span><span class="p">)</span>
<span class="n">test_scores_logreg5</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test5</span><span class="p">,</span> <span class="n">logreg_fit_test5</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training Accuracy 5 min: &quot;</span><span class="p">,</span> <span class="n">train_scores_logreg5</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Testing Accuracy 5 min: &quot;</span><span class="p">,</span> <span class="n">train_scores_logreg5</span><span class="p">)</span>

<span class="c1"># 10 min</span>
<span class="n">logreg10</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train10</span><span class="p">,</span> <span class="n">y_train10</span><span class="p">)</span>
<span class="n">logreg_fit_train10</span> <span class="o">=</span> <span class="n">logreg10</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train10</span><span class="p">)</span>
<span class="n">logreg_fit_test10</span> <span class="o">=</span> <span class="n">logreg10</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test10</span><span class="p">)</span>

<span class="n">train_scores_logreg10</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train10</span><span class="p">,</span> <span class="n">logreg_fit_train10</span><span class="p">)</span>
<span class="n">test_scores_logreg10</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test10</span><span class="p">,</span> <span class="n">logreg_fit_test10</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training Accuracy 10 min: &quot;</span><span class="p">,</span> <span class="n">train_scores_logreg10</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Testing Accuracy 10 min: &quot;</span><span class="p">,</span> <span class="n">train_scores_logreg10</span><span class="p">)</span>

<span class="c1"># 20 min</span>
<span class="n">logreg20</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train20</span><span class="p">,</span> <span class="n">y_train20</span><span class="p">)</span>
<span class="n">logreg_fit_train20</span> <span class="o">=</span> <span class="n">logreg20</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train20</span><span class="p">)</span>
<span class="n">logreg_fit_test20</span> <span class="o">=</span> <span class="n">logreg20</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test20</span><span class="p">)</span>

<span class="n">train_scores_logreg20</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train20</span><span class="p">,</span> <span class="n">logreg_fit_train20</span><span class="p">)</span>
<span class="n">test_scores_logreg20</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test20</span><span class="p">,</span> <span class="n">logreg_fit_test20</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training Accuracy 20 min: &quot;</span><span class="p">,</span> <span class="n">train_scores_logreg20</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Testing Accuracy 20 min: &quot;</span><span class="p">,</span> <span class="n">train_scores_logreg20</span><span class="p">)</span>

<span class="c1"># 30 min</span>
<span class="n">logreg30</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train30</span><span class="p">,</span> <span class="n">y_train30</span><span class="p">)</span>
<span class="n">logreg_fit_train30</span> <span class="o">=</span> <span class="n">logreg30</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train30</span><span class="p">)</span>
<span class="n">logreg_fit_test30</span> <span class="o">=</span> <span class="n">logreg30</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test30</span><span class="p">)</span>

<span class="n">train_scores_logreg30</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train30</span><span class="p">,</span> <span class="n">logreg_fit_train30</span><span class="p">)</span>
<span class="n">test_scores_logreg30</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test30</span><span class="p">,</span> <span class="n">logreg_fit_test30</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training Accuracy 30 min: &quot;</span><span class="p">,</span> <span class="n">train_scores_logreg30</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Testing Accuracy 30 min: &quot;</span><span class="p">,</span> <span class="n">train_scores_logreg30</span><span class="p">)</span>

<span class="c1"># 60 min</span>
<span class="n">logreg60</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">(</span><span class="n">C</span><span class="o">=</span><span class="mi">10000</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train60</span><span class="p">,</span> <span class="n">y_train60</span><span class="p">)</span>
<span class="n">logreg_fit_train60</span> <span class="o">=</span> <span class="n">logreg60</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train60</span><span class="p">)</span>
<span class="n">logreg_fit_test60</span> <span class="o">=</span> <span class="n">logreg60</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test60</span><span class="p">)</span>

<span class="n">train_scores_logreg60</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train60</span><span class="p">,</span> <span class="n">logreg_fit_train60</span><span class="p">)</span>
<span class="n">test_scores_logreg60</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test60</span><span class="p">,</span> <span class="n">logreg_fit_test60</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Training Accuracy 60 min: &quot;</span><span class="p">,</span> <span class="n">train_scores_logreg60</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Testing Accuracy 60 min: &quot;</span><span class="p">,</span> <span class="n">train_scores_logreg60</span><span class="p">)</span>
</pre></div>

    </div>
</div>
  
<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>



<div class="output_html rendered_html output_subarea ">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Interval</th>
      <th>training accuracy</th>
      <th>test accuracy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>4</th>
      <td>30 minute</td>
      <td>0.523760</td>
      <td>0.503306</td>
    </tr>
    <tr>
      <th>3</th>
      <td>20 minute</td>
      <td>0.515702</td>
      <td>0.500826</td>
    </tr>
    <tr>
      <th>5</th>
      <td>60 minute</td>
      <td>0.534946</td>
      <td>0.499586</td>
    </tr>
    <tr>
      <th>2</th>
      <td>10 minute</td>
      <td>0.491529</td>
      <td>0.476033</td>
    </tr>
    <tr>
      <th>1</th>
      <td>5 minute</td>
      <td>0.476033</td>
      <td>0.452893</td>
    </tr>
    <tr>
      <th>0</th>
      <td>1 minute</td>
      <td>0.468182</td>
      <td>0.451240</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>
          
<h1 id="l1-and-l2-regularization">L1 and L2 Regularization</h1>

<p>We then decided to incorporate regularization in an attempt to improve our logistic model's predictive ability. Lasso regularization (l1) sets the effects/coefficients of unimportant predictors to 0, whereas ridge (l2) simply minimizes/lowers those effects.</p>               
<p>First, lasso regularization:</p>
          
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="k">import</span> <span class="n">Lasso</span>
<span class="kn">from</span> <span class="nn">sklearn.linear_model</span> <span class="k">import</span> <span class="n">LogisticRegressionCV</span>

<span class="c1"># lasso</span>
<span class="n">lasso</span> <span class="o">=</span> <span class="n">LogisticRegressionCV</span><span class="p">(</span><span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="s1">&#39;l1&#39;</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;liblinear&#39;</span><span class="p">)</span>

<span class="n">train_scores_logreg_lasso</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">test_scores_logreg_lasso</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train_list</span><span class="p">)):</span>
    <span class="n">lassofit</span> <span class="o">=</span> <span class="n">lasso</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_list</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">y_train_list</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">y_pred_train_lasso</span> <span class="o">=</span> <span class="n">lassofit</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train_list</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">y_pred_test_lasso</span> <span class="o">=</span> <span class="n">lassofit</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_list</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">train_score</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train_list</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">y_pred_train_lasso</span><span class="p">)</span>
    <span class="n">test_score</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test_list</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">y_pred_test_lasso</span><span class="p">)</span>
    <span class="n">train_scores_logreg_lasso</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_score</span><span class="p">)</span>
    <span class="n">test_scores_logreg_lasso</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_score</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Training set accuracy score for </span><span class="si">{intervals[i]}</span><span class="s1"> using CV &amp; LASSO penalty: </span><span class="si">{train_score:.4f}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Test set accuracy score for </span><span class="si">{intervals[i]}</span><span class="s1"> using CV &amp; LASSO penalty: </span><span class="si">{test_score:.4f}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
          
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># output table</span>
<span class="n">logreg_lasso_df_ouptut</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Interval&quot;</span><span class="p">,</span> <span class="s2">&quot;training accuracy&quot;</span><span class="p">,</span> <span class="s2">&quot;test accuracy&quot;</span><span class="p">])</span>


<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">intervals</span><span class="p">)):</span>
    <span class="n">logreg_lasso_df_ouptut</span> <span class="o">=</span> <span class="n">logreg_lasso_df_ouptut</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
        <span class="s2">&quot;Interval&quot;</span><span class="p">:</span> <span class="n">intervals</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
        <span class="s2">&quot;training accuracy&quot;</span><span class="p">:</span>  <span class="n">train_scores_logreg_lasso</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
        <span class="s2">&quot;test accuracy&quot;</span> <span class="p">:</span> <span class="n">test_scores_logreg_lasso</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
          <span class="p">},</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">logreg_lasso_df_ouptut</span> <span class="o">=</span> <span class="n">logreg_lasso_df_ouptut</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s1">&#39;test accuracy&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">logreg_lasso_df_ouptut</span><span class="p">)</span>
</pre></div>

    </div>
</div>
          
<p>Now, ridge regularization:</p>

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># ridge</span>
<span class="n">ridge</span> <span class="o">=</span> <span class="n">LogisticRegressionCV</span><span class="p">(</span><span class="n">cv</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">penalty</span><span class="o">=</span><span class="s1">&#39;l2&#39;</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s1">&#39;liblinear&#39;</span><span class="p">)</span>

<span class="n">train_scores_logreg_ridge</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">test_scores_logreg_ridge</span> <span class="o">=</span> <span class="p">[]</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train_list</span><span class="p">)):</span>
    <span class="n">ridgefit</span> <span class="o">=</span> <span class="n">ridge</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train_list</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">y_train_list</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">y_pred_train_ridge</span> <span class="o">=</span> <span class="n">ridgefit</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train_list</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">y_pred_test_ridge</span> <span class="o">=</span> <span class="n">ridgefit</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test_list</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="n">train_score</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_train_list</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">y_pred_train_ridge</span><span class="p">)</span>
    <span class="n">test_score</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test_list</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">y_pred_test_ridge</span><span class="p">)</span>
    <span class="n">train_scores_logreg_ridge</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">train_score</span><span class="p">)</span>
    <span class="n">test_scores_logreg_ridge</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">test_score</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Training set accuracy score for </span><span class="si">{intervals[i]}</span><span class="s1"> using CV &amp; Ridge penalty:: </span><span class="si">{train_score:.4f}</span><span class="s1">&#39;</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;Test set accuracy score for </span><span class="si">{intervals[i]}</span><span class="s1"> using CV &amp; Ridge penalty:: </span><span class="si">{test_score:.4f}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
          
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># output table</span>
<span class="n">logreg_ridge_df_ouptut</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Interval&quot;</span><span class="p">,</span> <span class="s2">&quot;training accuracy&quot;</span><span class="p">,</span> <span class="s2">&quot;test accuracy&quot;</span><span class="p">])</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">intervals</span><span class="p">)):</span>
    <span class="n">logreg_ridge_df_ouptut</span> <span class="o">=</span> <span class="n">logreg_ridge_df_ouptut</span><span class="o">.</span><span class="n">append</span><span class="p">({</span>
        <span class="s2">&quot;Interval&quot;</span><span class="p">:</span> <span class="n">intervals</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
        <span class="s2">&quot;training accuracy&quot;</span><span class="p">:</span>  <span class="n">train_scores_logreg_ridge</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
        <span class="s2">&quot;test accuracy&quot;</span> <span class="p">:</span> <span class="n">test_scores_logreg_ridge</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
          <span class="p">},</span> <span class="n">ignore_index</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">logreg_ridge_df_ouptut</span> <span class="o">=</span> <span class="n">logreg_ridge_df_ouptut</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">by</span><span class="o">=</span><span class="s1">&#39;test accuracy&#39;</span><span class="p">,</span> <span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">logreg_ridge_df_ouptut</span><span class="p">)</span>
</pre></div>

    </div>
</div>

<p>Lasso Regularization does not perform well, whereas ridge gets us just above 50% accuracy on the test set. This suggests that a few predictors may have significant impact and are being pushed to 0 improperly in lasso.</p>
          
<h1 id="random-forest">Random Forest</h1>

<p>Our first ensemble method is random forest, which randomly subsets predictors upon which to generate decision trees. We tested out a few different tree depth and number parameters ourselves and determined that a depth of 5 and number of trees of 100 was ideal for our analysis.</p>

<p>Below is sample code for one of the time interval models. We perform this for each of the models, and the results can bee seen below this code.</p>
          
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># Calibrate num trees and tree depth (after having tried different parameters, saw comparable results)</span>
<span class="n">n_trees</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">tree_depth</span> <span class="o">=</span> <span class="mi">5</span>
</pre></div>

    </div>
</div>

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># create RF models</span>
<span class="n">forest_model0</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="n">n_trees</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="n">tree_depth</span><span class="p">,</span> 
                                      <span class="n">max_features</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">np_X_train0</span><span class="p">[</span><span class="mi">0</span><span class="p">]))))</span>

<span class="n">forest_model5</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="n">n_trees</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="n">tree_depth</span><span class="p">,</span> 
                                      <span class="n">max_features</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">np_X_train5</span><span class="p">[</span><span class="mi">0</span><span class="p">]))))</span>

<span class="n">forest_model10</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="n">n_trees</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="n">tree_depth</span><span class="p">,</span> 
                                      <span class="n">max_features</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">np_X_train10</span><span class="p">[</span><span class="mi">0</span><span class="p">]))))</span>

<span class="n">forest_model20</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="n">n_trees</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="n">tree_depth</span><span class="p">,</span> 
                                      <span class="n">max_features</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">np_X_train20</span><span class="p">[</span><span class="mi">0</span><span class="p">]))))</span>

<span class="n">forest_model30</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="n">n_trees</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="n">tree_depth</span><span class="p">,</span> 
                                      <span class="n">max_features</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">np_X_train30</span><span class="p">[</span><span class="mi">0</span><span class="p">]))))</span>

<span class="n">forest_model60</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="n">n_trees</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="n">tree_depth</span><span class="p">,</span> 
                                      <span class="n">max_features</span><span class="o">=</span><span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">np_X_train60</span><span class="p">[</span><span class="mi">0</span><span class="p">]))))</span>
</pre></div>

    </div>
</div>
          
div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># fit and calculate accuracy</span>
<span class="n">forest_model0</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">np_X_train0</span><span class="p">,</span> <span class="n">np_y_train0</span><span class="p">)</span>
<span class="n">y_pred0_forest_train</span> <span class="o">=</span> <span class="n">forest_model0</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np_X_train0</span><span class="p">)</span>
<span class="n">y_pred0_forest_test</span> <span class="o">=</span> <span class="n">forest_model0</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np_X_test0</span><span class="p">)</span>

<span class="n">random_forest_train_score0</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">np_y_train0</span><span class="p">,</span> <span class="n">y_pred0_forest_train</span><span class="p">)</span>
<span class="n">random_forest_test_score0</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">np_y_test0</span><span class="p">,</span> <span class="n">y_pred0_forest_test</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;The random forest accuracy on the training set: </span><span class="si">{random_forest_train_score0}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;The random forest accuracy on the test set: </span><span class="si">{random_forest_test_score0:.4f}</span><span class="s1">&#39;</span><span class="p">)</span>
</pre></div>

    </div>
</div>
        
<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>



<div class="output_html rendered_html output_subarea ">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Interval</th>
      <th>training accuracy</th>
      <th>test accuracy</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>5</th>
      <td>60 minute</td>
      <td>0.620968</td>
      <td>0.545906</td>
    </tr>
    <tr>
      <th>3</th>
      <td>20 minute</td>
      <td>0.623347</td>
      <td>0.532231</td>
    </tr>
    <tr>
      <th>4</th>
      <td>30 minute</td>
      <td>0.611777</td>
      <td>0.514050</td>
    </tr>
    <tr>
      <th>2</th>
      <td>10 minute</td>
      <td>0.635331</td>
      <td>0.508264</td>
    </tr>
    <tr>
      <th>0</th>
      <td>1 minute</td>
      <td>0.547934</td>
      <td>0.455372</td>
    </tr>
    <tr>
      <th>1</th>
      <td>5 minute</td>
      <td>0.591116</td>
      <td>0.446281</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>
       
<p>Random Forest performs decently relative to our original goal in the project (achieving above 50% test accuracy).</p>
      
<h1 id="boosting">Boosting</h1>
<p>Next, we considered boosting, an iterative approach that might eliminate some more of the error from above. Note that the RF model is based on fully grown trees, meaning it is susceptible to low bias and high variance in its results. Boosting, however is based on 'weaker' learners meaning high bias and low variance.</p>
<p>Below is sample code for one of the time interval models. We perform this for each of the models, and the results can bee seen below this code.</p>
        
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># initialize parameters like for RF, much the same process - tested different ones and saw best/most consistent results with the following</span>
<span class="n">estimators_ADA</span> <span class="o">=</span> <span class="mi">40</span>
<span class="n">learning_ADA</span> <span class="o">=</span> <span class="mf">0.01</span>
<span class="n">tree_depth</span> <span class="o">=</span> <span class="mi">10</span>
</pre></div>

    </div>
</div>
        
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">model_ADA0</span> <span class="o">=</span> <span class="n">AdaBoostClassifier</span><span class="p">(</span><span class="n">base_estimator</span><span class="o">=</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="n">tree_depth</span><span class="p">),</span> 
                               <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_ADA</span><span class="p">,</span> <span class="n">n_estimators</span><span class="o">=</span><span class="n">estimators_ADA</span><span class="p">)</span>
<span class="n">model_ADA0</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">np_X_train0</span><span class="p">,</span> <span class="n">np_y_train0</span><span class="p">)</span>

<span class="n">y_train_pred_ADA0</span> <span class="o">=</span> <span class="n">model_ADA0</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np_X_train0</span><span class="p">)</span>
<span class="n">y_test_pred_ADA0</span> <span class="o">=</span> <span class="n">model_ADA0</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">np_X_test0</span><span class="p">)</span>
<span class="n">ADA_train0</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">np_y_train0</span><span class="p">,</span> <span class="n">y_train_pred_ADA0</span><span class="p">)</span>
<span class="n">ADA_test0</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">np_y_test0</span><span class="p">,</span> <span class="n">y_test_pred_ADA0</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;The ADABoost accuracy on the training set: </span><span class="si">{ADA_train0}</span><span class="s1">&#39;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;The ADABoost accuracy on the test set: </span><span class="si">{ADA_test0:.4f}</span><span class="s1">&#39;</span><span class="p">)</span>

<span class="n">ADA_train0_staged</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">model_ADA0</span><span class="o">.</span><span class="n">staged_score</span><span class="p">(</span><span class="n">np_X_train0</span><span class="p">,</span> <span class="n">np_y_train0</span><span class="p">))</span>
<span class="n">ADA_test0_staged</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">model_ADA0</span><span class="o">.</span><span class="n">staged_score</span><span class="p">(</span><span class="n">np_X_test0</span><span class="p">,</span> <span class="n">np_y_test0</span><span class="p">))</span>

</pre></div>

    </div>
</div>
        
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># your code here</span>
<span class="c1"># define function to abstract process of building plot</span>
<span class="k">def</span> <span class="nf">baselearner_plt</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">):</span>
    <span class="c1"># AdaBoostClassifier</span>
    <span class="n">ada</span> <span class="o">=</span> <span class="n">AdaBoostClassifier</span><span class="p">(</span><span class="n">DecisionTreeClassifier</span><span class="p">(</span><span class="n">max_depth</span><span class="o">=</span><span class="n">n</span><span class="p">),</span> <span class="n">n_estimators</span><span class="o">=</span><span class="mi">30</span><span class="p">,</span> <span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.05</span><span class="p">)</span>
    <span class="n">ada</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    
    <span class="c1"># staged_score train to plot</span>
    <span class="n">ada_predicts_train</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">ada</span><span class="o">.</span><span class="n">staged_score</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ada_predicts_train</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s2">&quot;Train&quot;</span><span class="p">);</span>

    <span class="c1"># staged_score test to plot</span>
    <span class="n">ada_predicts_test</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">ada</span><span class="o">.</span><span class="n">staged_score</span><span class="p">(</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">))</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">ada_predicts_test</span><span class="p">,</span> <span class="n">label</span> <span class="o">=</span> <span class="s2">&quot;Test&quot;</span><span class="p">);</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">fontsize</span><span class="o">=</span><span class="mi">14</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;AdaBoost Classifier Accuracy&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Accuracy&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Num Iterations&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">16</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
    
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Maximum test accuracy for depth of &quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">n</span><span class="p">)</span><span class="o">+</span><span class="s2">&quot; is &quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">ada_predicts_test</span><span class="p">))</span><span class="o">+</span><span class="s2">&quot; at &quot;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">ada_predicts_test</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">ada_predicts_test</span><span class="p">)))</span><span class="o">+</span><span class="s2">&quot; iterations&quot;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">X_train_list</span><span class="p">)):</span>
    <span class="n">baselearner_plt</span><span class="p">(</span><span class="n">tree_depth</span><span class="p">,</span> <span class="n">X_train_list</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">y_train_list</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">X_test_list</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">y_test_list</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Time Interval: &quot;</span><span class="p">,</span> <span class="n">intervals</span><span class="p">[</span><span class="n">i</span><span class="p">])</span> 
    
</pre></div>

    </div>
</div>
        
<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="output_boost0.png">
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Maximum test accuracy for depth of 10 is 0.4818181818181818 at 2 iterations
Time Interval:  1 minute
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="output_boost5.png">
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Maximum test accuracy for depth of 10 is 0.5107438016528926 at 8 iterations
Time Interval:  5 minute
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="output_boost10.png">
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Maximum test accuracy for depth of 10 is 0.5958677685950413 at 9 iterations
Time Interval:  10 minute
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="output_boost20.png">
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre>Maximum test accuracy for depth of 10 is 0.6090909090909091 at 21 iterations
Time Interval:  20 minute
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="output_boost30.png">
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre> Maximum test accuracy for depth of 10 is 0.6347107438016529 at 29 iterations
Time Interval:  30 minute
</pre>
</div>
</div>

<div class="output_area">

    <div class="prompt"></div>




<div class="output_png output_subarea ">
<img src="output_boost60.png">
</div>

</div>

<div class="output_area">

    <div class="prompt"></div>


<div class="output_subarea output_stream output_stdout output_text">
<pre> Maximum test accuracy for depth of 10 is 0.6683209263854425 at 5 iterations
Time Interval:  60 minute
</pre>
</div>
</div>

</div>
</div>

<p>Boosting performs relatively well when comparing all the models. Let's try a NN to see if we can do better, though.</p>
        
<h1 id="neural-networks">Neural Networks</h1>

<p>Finally, we created an artificial neural network to classify our outcomes.</p>

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># prepare model</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">models</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5</span><span class="p">):</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;relu&#39;</span><span class="p">))</span>
    <span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">layers</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="mf">0.3</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">Dense</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">activation</span><span class="o">=</span><span class="s1">&#39;sigmoid&#39;</span><span class="p">))</span>
<span class="n">model</span><span class="o">.</span><span class="n">compile</span><span class="p">(</span><span class="n">loss</span><span class="o">=</span><span class="s1">&#39;binary_crossentropy&#39;</span><span class="p">,</span> <span class="n">optimizer</span><span class="o">=</span><span class="s1">&#39;adam&#39;</span><span class="p">,</span> <span class="n">metrics</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;accuracy&#39;</span><span class="p">])</span>

<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># define parameters</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">batch_size</span> <span class="o">=</span> <span class="mi">12</span>
<span class="n">validation_split</span> <span class="o">=</span> <span class="mf">0.3</span>     
   
<div class=" highlight hl-ipython3"><pre><span></span><span class="c1"># fit model</span>
<span class="n">history0</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">np_X_train0_NN</span><span class="p">,</span> <span class="n">np_y_train0_NN</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="n">validation_split</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">history5</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">np_X_train5_NN</span><span class="p">,</span> <span class="n">np_y_train5_NN</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="n">validation_split</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">history10</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">np_X_train10_NN</span><span class="p">,</span> <span class="n">np_y_train10_NN</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="n">validation_split</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">history20</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">np_X_train20_NN</span><span class="p">,</span> <span class="n">np_y_train20_NN</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="n">validation_split</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">history30</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">np_X_train30_NN</span><span class="p">,</span> <span class="n">np_y_train30_NN</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="n">validation_split</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">history60</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">np_X_train60_NN</span><span class="p">,</span> <span class="n">np_y_train60_NN</span><span class="p">,</span> <span class="n">validation_split</span><span class="o">=</span><span class="n">validation_split</span><span class="p">,</span> <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>   


<div class="output_wrapper">
<div class="output">


<div class="output_area">

    <div class="prompt"></div>



<div class="output_html rendered_html output_subarea ">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Interval</th>
      <th>training accuracy</th>
      <th>val accuracy</th>
      <th>val loss</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>5</th>
      <td>60 minute</td>
      <td>0.844609</td>
      <td>0.618194</td>
      <td>0.369464</td>
    </tr>
    <tr>
      <th>4</th>
      <td>30 minute</td>
      <td>0.843566</td>
      <td>0.606749</td>
      <td>0.376075</td>
    </tr>
    <tr>
      <th>3</th>
      <td>20 minute</td>
      <td>0.826741</td>
      <td>0.583333</td>
      <td>0.402431</td>
    </tr>
    <tr>
      <th>0</th>
      <td>1 minute</td>
      <td>0.789256</td>
      <td>0.573691</td>
      <td>0.426097</td>
    </tr>
    <tr>
      <th>2</th>
      <td>10 minute</td>
      <td>0.817001</td>
      <td>0.570248</td>
      <td>0.413901</td>
    </tr>
    <tr>
      <th>1</th>
      <td>5 minute</td>
      <td>0.784829</td>
      <td>0.554408</td>
      <td>0.442316</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

<p>Even after changing hyperparameters, our neural network performs pretty much in line with our other models and slightly below boosting.</p>

</div>
<div class="cell border-box-sizing code_cell rendered">
<div class="input">
<div class="prompt input_prompt">In&nbsp;[&nbsp;]:</div>
<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span> 
</pre></div>

    </div>
</div>
</div>

</div>

    </div>
</div>
</div>

<hr />

<h1 id="model-selection">Model Selection</h1>

<p>Based upon the presented analysis, we conclude that our boosted decision tree classifier, at a depth of 2 with 751 iterations, is the best model. It achieves the highest accuracy in the test set, of 93.0%.</p>



          
        </div>
      </div>
    </div>
  </div>
</html>
